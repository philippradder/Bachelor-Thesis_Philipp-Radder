{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0bc40ed",
   "metadata": {},
   "source": [
    "## Evaluation of the Solution Space under different conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867b4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure necessary packages are installed\n",
    "!pip install cobra efmtool numpy pandas scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79fd1b9",
   "metadata": {},
   "source": [
    "Definition of the EV Network from Eberhard Voit's \"A first course in Systems Biology\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd555b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaktionen: ['r1_in', 'r2', 'r3', 'r4_out', 'r5', 'r6r', 'r7', 'r8r_out', 'r9_out']\n",
      "Metaboliten: ['A_e', 'A', 'C', 'D', 'E', 'D_e', 'B', 'B_e', 'E_e']\n",
      "Gene: []\n"
     ]
    }
   ],
   "source": [
    "from cobra import Model, Reaction, Metabolite\n",
    "\n",
    "# Modell erstellen\n",
    "model = Model(\"Toy_Network\")\n",
    "\n",
    "# Metaboliten definieren (intern)\n",
    "A = Metabolite(\"A\", compartment=\"c\")\n",
    "B = Metabolite(\"B\", compartment=\"c\")\n",
    "C = Metabolite(\"C\", compartment=\"c\")\n",
    "D = Metabolite(\"D\", compartment=\"c\")\n",
    "E = Metabolite(\"E\", compartment=\"c\")\n",
    "\n",
    "# Metaboliten definieren (extern)\n",
    "A_e = Metabolite(\"A_e\", compartment=\"e\")\n",
    "B_e = Metabolite(\"B_e\", compartment=\"e\")\n",
    "D_e = Metabolite(\"D_e\", compartment=\"e\")\n",
    "E_e = Metabolite(\"E_e\", compartment=\"e\")\n",
    "\n",
    "# Reaktionen definieren\n",
    "r1_in = Reaction(\"r1_in\")\n",
    "r1_in.name = \"A import\"\n",
    "r1_in.lower_bound = 0\n",
    "r1_in.upper_bound = 1000\n",
    "r1_in.add_metabolites({A_e: -1, A: 1})\n",
    "\n",
    "r2 = Reaction(\"r2\")\n",
    "r2.name = \"A to C\"\n",
    "r2.lower_bound = 0\n",
    "r2.upper_bound = 1000\n",
    "r2.add_metabolites({A: -1, C: 1})\n",
    "\n",
    "r3 = Reaction(\"r3\")\n",
    "r3.name = \"C to D and E\"\n",
    "r3.lower_bound = 0\n",
    "r3.upper_bound = 1000\n",
    "r3.add_metabolites({C: -1, D: 1, E: 1})\n",
    "\n",
    "r4_out = Reaction(\"r4_out\")\n",
    "r4_out.name = \"D export\"\n",
    "r4_out.lower_bound = 0\n",
    "r4_out.upper_bound = 1000\n",
    "r4_out.add_metabolites({D: -1, D_e: 1})\n",
    "\n",
    "r5 = Reaction(\"r5\")\n",
    "r5.name = \"A to B\"\n",
    "r5.lower_bound = 0\n",
    "r5.upper_bound = 1000\n",
    "r5.add_metabolites({A: -1, B: 1})\n",
    "\n",
    "r6r = Reaction(\"r6r\")\n",
    "r6r.name = \"B to C\"\n",
    "r6r.lower_bound = -1000\n",
    "r6r.upper_bound = 1000\n",
    "r6r.add_metabolites({B: -1, C: 1})\n",
    "\n",
    "r7 = Reaction(\"r7\")\n",
    "r7.name = \"B to D\"\n",
    "r7.lower_bound = 0\n",
    "r7.upper_bound = 1000\n",
    "r7.add_metabolites({B: -1, D: 1})\n",
    "\n",
    "r8r_out = Reaction(\"r8r_out\")\n",
    "r8r_out.name = \"B import\"\n",
    "r8r_out.lower_bound = -1000\n",
    "r8r_out.upper_bound = 1000\n",
    "r8r_out.add_metabolites({B_e: -1, B: 1})\n",
    "\n",
    "r9_out = Reaction(\"r9_out\")\n",
    "r9_out.name = \"E export\"\n",
    "r9_out.lower_bound = 0\n",
    "r9_out.upper_bound = 1000\n",
    "r9_out.add_metabolites({E: -1, E_e: 1})\n",
    "\n",
    "# Reaktionen zum Modell hinzufügen\n",
    "model.add_reactions([r1_in, r2, r3, r4_out, r5, r6r, r7, r8r_out, r9_out])\n",
    "\n",
    "# Modell überprüfen\n",
    "print(\"Reaktionen:\", [rxn.id for rxn in model.reactions])\n",
    "print(\"Metaboliten:\", [met.id for met in model.metabolites])\n",
    "print(\"Gene:\", [gene.id for gene in model.genes])\n",
    "\n",
    "# Modell speichern (optional)\n",
    "#model.save(\"toy_network.xml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f24d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cobra\n",
    "\n",
    "\n",
    "def get_stoichiometric_matrix(model):\n",
    "    # Filtere die Reaktionen, um nur Reaktionen zu behalten, die nicht mit \"EX_\" beginnen\n",
    "    internal_reactions = [rxn for rxn in model.reactions if not rxn.id.startswith(\"EX_\")]\n",
    "\n",
    "    # Extrahiere die Metaboliten aus dem Modell\n",
    "    internal_metabolites = [meta for meta in model.metabolites if not meta.compartment == 'e']\n",
    "\n",
    "    # Erstelle die leere Stöchiometrie-Matrix mit (Anzahl der Metaboliten, Anzahl der internen Reaktionen)\n",
    "    stoichiometric_matrix = np.zeros((len(internal_metabolites), len(internal_reactions)))\n",
    "\n",
    "    # Befülle die Stöchiometrie-Matrix so, dass jede Spalte eine Reaktion repräsentiert\n",
    "    for j, rxn in enumerate(internal_reactions):  # Spaltenweise über Reaktionen iterieren\n",
    "        for i, met in enumerate(internal_metabolites):  # Zeilenweise über Metaboliten iterieren\n",
    "            stoichiometric_matrix[i, j] = rxn.metabolites.get(met, 0)  # Falls Metabolit nicht in der Reaktion ist, wird 0 zurückgegeben\n",
    "    return stoichiometric_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "986f9a64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stoichiometric matrix shape: (5, 9)\n",
      "Stoichiometric matrix: [[ 1. -1.  0.  0. -1.  0.  0.  0.  0.]\n",
      " [ 0.  1. -1.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  1. -1.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0. -1.]\n",
      " [ 0.  0.  0.  0.  1. -1. -1.  1.  0.]]\n",
      "Reversibilities: [0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "Number of reactions: 9\n",
      "2025-01-03  21:33:10.433  main                     INFO     | logger initialized\n",
      "2025-01-03  21:33:10.434  main                     INFO     | =====================================================\n",
      "2025-01-03  21:33:10.434  main                     INFO     | efmtool version 4.7.1, 2009-12-04 18:30:05\n",
      "2025-01-03  21:33:10.435  main                     INFO     | Copyright (c) 2009, Marco Terzer, Zurich, Switzerland\n",
      "2025-01-03  21:33:10.435  main                     INFO     | This is free software, !!! NO WARRANTY !!!\n",
      "2025-01-03  21:33:10.435  main                     INFO     | See LICENCE.txt for redistribution conditions\n",
      "2025-01-03  21:33:10.435  main                     INFO     | =====================================================\n",
      "2025-01-03  21:33:10.495  main    efm.output.mat   INFO     | estimated efms-per-file: 29000000\n",
      "2025-01-03  21:33:10.509  main    efm.impl         INFO     | Elemetary flux mode computation\n",
      "2025-01-03  21:33:10.509  main    efm.impl         INFO     | Implementation:\n",
      "2025-01-03  21:33:10.509  main    efm.impl         INFO     | ..algorithm name   : SequentialDoubleDescriptionImpl\n",
      "2025-01-03  21:33:10.509  main    efm.impl         INFO     | ..model type       : NullspaceEfmModel\n",
      "2025-01-03  21:33:10.509  main    efm.impl         INFO     | ..memory type      : InCoreMemory\n",
      "2025-01-03  21:33:10.509  main    efm.impl         INFO     | ..output type      : MatFile\n",
      "2025-01-03  21:33:10.509  main    efm.impl         INFO     | System:\n",
      "2025-01-03  21:33:10.531  main    efm.impl         INFO     | ..hostname         : MBPvonPhilipp2.fritz.box\n",
      "2025-01-03  21:33:10.531  main    efm.impl         INFO     | ..operating system : aarch64/Mac OS X/13.5\n",
      "2025-01-03  21:33:10.531  main    efm.impl         INFO     | ..processors       : 10\n",
      "2025-01-03  21:33:10.531  main    efm.impl         INFO     | ..vm               : Amazon.com Inc./OpenJDK 64-Bit Server VM/11.0.24+8-LTS\n",
      "2025-01-03  21:33:10.531  main    efm.impl         INFO     | ..vm-spec          : Oracle Corporation/Java Virtual Machine Specification/11\n",
      "2025-01-03  21:33:10.531  main    efm.impl         INFO     | ..vm arguments     : []\n",
      "2025-01-03  21:33:10.532  main    efm.impl         INFO     | ..memory, commited : 10M\n",
      "2025-01-03  21:33:10.532  main    efm.impl         INFO     | ..memory, used     : 4M\n",
      "2025-01-03  21:33:10.532  main    efm.impl         INFO     | Config:\n",
      "2025-01-03  21:33:10.532  main    efm.impl         INFO     | ..generator        : Efm\n",
      "2025-01-03  21:33:10.532  main    efm.impl         INFO     | ..adj method       : pattern-tree-minzero\n",
      "2025-01-03  21:33:10.532  main    efm.impl         INFO     | ..row ordering     : MostZerosOrAbsLexMin\n",
      "2025-01-03  21:33:10.532  main    efm.impl         INFO     | ..arithmetic       : double (prec: -1 / zero: 1.0E-10)\n",
      "2025-01-03  21:33:10.532  main    efm.impl         INFO     | ..compression      : on\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..compr. methods   : [CoupledZero, CoupledContradicting, CoupledCombine, UniqueFlows, DeadEnd, Recursive]\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..normalize        : min\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..max threads      : 10\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..self test        : off\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..progress type    : None\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..progress part.   : 100\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..suppress         : []\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..enforce          : []\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..nosplit          : []\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..temp dir         : /var/folders/7q/2twr6y1j0x51j8zq3yycrys40000gn/T/tmpcj064vgr/???\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..flag             : (none)\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | Distributed Config:\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..node count       : 2\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..nodes            : [localhost, localhost]\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..vmargs           : [-Xmx800M, -Xmx500M]\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..command          : /usr/bin/java [vmargs] -cp [classpath] [class] [args]\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..partition        : 256\n",
      "2025-01-03  21:33:10.533  main    efm.impl         INFO     | ..cand. threshold  : 100000\n",
      "2025-01-03  21:33:10.534  main    efm.impl         INFO     | original network: 5 metabolites, 9 reactions (2 reversible)\n",
      "2025-01-03  21:33:10.545  main    efm.impl         INFO     | compressed network: 2 metabolites, 6 reactions (2 reversible)\n",
      "2025-01-03  21:33:10.559  main    efm.impl         INFO     | stoich expanded has dimensions 2x8\n",
      "2025-01-03  21:33:10.559  main    efm.impl         INFO     | kernel matrix has dimensions 8x6\n",
      "2025-01-03  21:33:10.559  main    efm.impl         INFO     | TIME preprocessing: 63ms\n",
      "2025-01-03  21:33:10.562  main    efm.impl         INFO     | iteration 0/2: 6 modes, dt=0ms.\t{ next 1/2: 2 adj candidates, [+/0/-] = [2/3/1] }\n",
      "2025-01-03  21:33:10.567  main    efm.impl         INFO     | iteration 1/2: 7 modes, dt=5ms.\t{ next 2/2: 6 adj candidates, [+/0/-] = [3/2/2] }\n",
      "2025-01-03  21:33:10.570  main    efm.impl         INFO     | iteration 2/2: 10 modes, dt=3ms.\n",
      "2025-01-03  21:33:10.570  main    efm.impl         INFO     | TIME iterate: 9ms\n",
      "2025-01-03  21:33:10.570  main    efm.impl         INFO     | efm count before postprocessing: 10\n",
      "2025-01-03  21:33:10.571  main    efm.impl         INFO     | efm count after filtering/consolidation: 8\n",
      "2025-01-03  21:33:10.571  main    efm.impl         INFO     | uncompressing modes (can take a while)\n",
      "2025-01-03  21:33:10.583  main    efm.impl         INFO     | TIME postprocessing: 13ms\n",
      "2025-01-03  21:33:10.583  main    efm.impl         INFO     | overall computation time: 87ms\n",
      "Berechnete Elementarmoden:\n",
      "[['r1_in' '1.0' '1.0' '1.0' '0.0' '1.0' '1.0' '1.0' '0.0']\n",
      " ['r2' '1.0' '0.0' '0.0' '0.0' '0.0' '1.0' '1.0' '0.0']\n",
      " ['r3' '0.0' '0.0' '0.0' '0.0' '1.0' '1.0' '0.0' '1.0']\n",
      " ['r4_out' '0.0' '0.0' '1.0' '1.0' '1.0' '1.0' '1.0' '1.0']\n",
      " ['r5' '0.0' '1.0' '1.0' '0.0' '1.0' '0.0' '0.0' '0.0']\n",
      " ['r6r' '-1.0' '0.0' '0.0' '0.0' '1.0' '0.0' '-1.0' '1.0']\n",
      " ['r7' '0.0' '0.0' '1.0' '1.0' '0.0' '0.0' '1.0' '0.0']\n",
      " ['r8r_out' '-1.0' '-1.0' '0.0' '1.0' '0.0' '0.0' '0.0' '1.0']\n",
      " ['r9_out' '0.0' '0.0' '0.0' '0.0' '1.0' '1.0' '0.0' '1.0']]\n"
     ]
    }
   ],
   "source": [
    "import efmtool\n",
    "import cobra\n",
    "import numpy as np\n",
    "from efmtool import calculate_efms\n",
    "\n",
    "def cobra_to_efms(model):\n",
    "    # 1. Stoichiometric matrix (S matrix)\n",
    "    metabolites = [\n",
    "    metabolite for metabolite in model.metabolites \n",
    "    if metabolite.compartment == \"c\"\n",
    "    ]\n",
    "    reactions = model.reactions\n",
    "    stoichiometry = np.zeros((len(metabolites), len(reactions)))\n",
    "    #stoichiometry = get_stoichiometric_matrix(model)\n",
    "    \n",
    "    for i, met in enumerate(metabolites):\n",
    "        for j, rxn in enumerate(reactions):\n",
    "            try:\n",
    "                stoichiometry[i, j] = rxn.get_coefficient(met.id)\n",
    "            except KeyError:\n",
    "                \n",
    "                stoichiometry[i, j] = 0.0\n",
    "    \n",
    "    print(\"Stoichiometric matrix shape:\", stoichiometry.shape)\n",
    "    print(\"Stoichiometric matrix:\", stoichiometry)\n",
    "\n",
    "    # 2. Reversibilities: 1 for reversible, 0 for irreversible reactions\n",
    "    reversibilities = [1 if rxn.reversibility else 0 for rxn in reactions]\n",
    "    \n",
    "    print(\"Reversibilities:\", reversibilities)\n",
    "    print(\"Number of reactions:\", len(reactions))\n",
    "\n",
    "    # 3. Reaction names\n",
    "    reaction_names = [rxn.id for rxn in reactions]\n",
    "    \n",
    "    # 4. Metabolite names\n",
    "    metabolite_names = [met.id for met in metabolites]\n",
    "    \n",
    "    return calculate_efms(stoichiometry, reversibilities, reaction_names, metabolite_names), reaction_names\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 6. Berechne die Elementarmoden (EFMs) mit dem efmtool und Reaktionsnamen\n",
    "efms, reaction_names = cobra_to_efms(model)\n",
    "\n",
    "# 7. Ergebnisse anzeigen\n",
    "print(\"Berechnete Elementarmoden:\")\n",
    "print(np.column_stack((reaction_names, efms)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62cd64e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r1_in': 1.0, 'r4_out': 0.0, 'r8r_out': -1.0, 'r9_out': 0.0}\n",
      "{'r1_in': 1.0, 'r4_out': 0.0, 'r8r_out': -1.0, 'r9_out': 0.0}\n",
      "{'r1_in': 1.0, 'r4_out': 1.0, 'r8r_out': 0.0, 'r9_out': 0.0}\n",
      "{'r1_in': 0.0, 'r4_out': 1.0, 'r8r_out': 1.0, 'r9_out': 0.0}\n",
      "{'r1_in': 1.0, 'r4_out': 1.0, 'r8r_out': 0.0, 'r9_out': 1.0}\n",
      "{'r1_in': 1.0, 'r4_out': 1.0, 'r8r_out': 0.0, 'r9_out': 1.0}\n",
      "{'r1_in': 1.0, 'r4_out': 1.0, 'r8r_out': 0.0, 'r9_out': 0.0}\n",
      "{'r1_in': 0.0, 'r4_out': 1.0, 'r8r_out': 1.0, 'r9_out': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "input_array = np.column_stack((reaction_names, efms))\n",
    "\n",
    "# Extract headers and values\n",
    "headers = input_array[:, 0]\n",
    "values = input_array[:, 1:].astype(float)  # Convert values to float\n",
    "\n",
    "# Construct dictionaries\n",
    "experimental_data = []\n",
    "for col_idx in range(values.shape[1]):\n",
    "    data_point = {}\n",
    "    for row_idx, header in enumerate(headers):\n",
    "        if header.endswith(\"_in\") or header.endswith(\"_out\"):\n",
    "            # Add only reactions ending with \"_in\" or \"_out\"\n",
    "            data_point[header] = values[row_idx, col_idx]\n",
    "    # Normalize so \"A_in\" is always 1.0\n",
    "    if \"A_in\" in data_point and data_point[\"A_in\"] != 0.0:\n",
    "        normalization_factor = data_point[\"A_in\"]\n",
    "        for key in data_point.keys():\n",
    "            data_point[key] /= normalization_factor\n",
    "    experimental_data.append(data_point)\n",
    "\n",
    "# Output the result\n",
    "for data in experimental_data:\n",
    "    print(data)\n",
    "\n",
    "experimental_data_zeropadded_out = experimental_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d081e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.123498217099662e-08, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import lsq_linear\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(reaction_ids)\n",
    "# Funktion zur Ableitung des Zielvektors aus den experimentellen Daten\n",
    "def create_target_vector(data_point, reaction_ids):\n",
    "    target_flux = np.full(len(reaction_ids), np.nan)  # Vektor mit NaN initialisieren\n",
    "    for rxn_id, value in data_point.items():\n",
    "        if rxn_id in reaction_ids:  # Nur Reaktionen, die im Modell existieren\n",
    "            idx = reaction_ids.index(rxn_id)\n",
    "            target_flux[idx] = value  # Setze den Zielwert\n",
    "    return target_flux\n",
    "\n",
    "\n",
    "def least_square_min(model, S, experimental_data):\n",
    "    reaction_ids = [rxn.id for rxn in model.reactions if not rxn.id.startswith(\"EX_\")]\n",
    "    total_score = 0.0\n",
    "    successful_optimizations = 0\n",
    "\n",
    "    for data_point in experimental_data:\n",
    "        # Zielvektor für aktuellen Datenpunkt erstellen\n",
    "        target_flux = create_target_vector(data_point, reaction_ids)\n",
    "\n",
    "        # Filter für bekannte Flüsse (Reaktionen, die in 'target_flux' nicht NaN sind)\n",
    "        known_flux_indices = ~np.isnan(target_flux)\n",
    "        target_flux_values = target_flux[known_flux_indices]\n",
    "\n",
    "        def objective(x):\n",
    "            return np.linalg.norm(x[known_flux_indices] - target_flux_values)\n",
    "\n",
    "        constraints = {'type': 'eq', 'fun': lambda x: np.dot(S, x)}\n",
    "\n",
    "        initial_guess = np.zeros(len(reaction_ids))\n",
    "        bounds = [(model.reactions.get_by_id(rxn_id).lower_bound,\n",
    "                   model.reactions.get_by_id(rxn_id).upper_bound)\n",
    "                  for rxn_id in reaction_ids]\n",
    "\n",
    "        result = minimize(objective, initial_guess, constraints=constraints, bounds=bounds, tol=1e-10)\n",
    "\n",
    "        if result.success:\n",
    "            optimized_flux = result.x\n",
    "            total_score += np.linalg.norm(optimized_flux[known_flux_indices] - target_flux_values)\n",
    "            successful_optimizations += 1\n",
    "        else:\n",
    "            print(f\"Optimization failed for data point: {data_point}. Message: {result.message}\")\n",
    "\n",
    "    # Return None if any optimization failed, otherwise the total score\n",
    "    if successful_optimizations < len(experimental_data):\n",
    "        return 0.0, len(experimental_data)\n",
    "    else:\n",
    "        return total_score, len(experimental_data)\n",
    "\n",
    " \n",
    "S = get_stoichiometric_matrix(model)\n",
    "print(least_square_min(model, S, experimental_data_zeropadded_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3691cd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of random reactions generated: 2000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from cobra import Reaction\n",
    "\n",
    "# Erstellen von Reaktionen mit 1-2 Substrat(en) und 1-2 Produkt(en)\n",
    "def generate_random_reactions(model, num_reactions=2000):\n",
    "    # Filter out metabolites that end with '_EX'\n",
    "    metabolites = [met for met in model.metabolites if not met.compartment == 'e']\n",
    "    random_reactions = []\n",
    "\n",
    "    for i in range(num_reactions):\n",
    "        reaction_valid = False\n",
    "\n",
    "        while not reaction_valid:\n",
    "            # Zufällige Auswahl der Anzahl an Substraten und Produkten\n",
    "            num_reactants = random.randint(1, 2)\n",
    "            num_products = random.randint(1, 2)\n",
    "\n",
    "            # Zufällige Auswahl der Substrate und Produkte\n",
    "            reactants = random.sample(metabolites, num_reactants)\n",
    "            products = random.sample(metabolites, num_products)\n",
    "\n",
    "            # Check, dass auf beiden Seiten Metaboliten vorhanden sind\n",
    "            if set(reactants).isdisjoint(set(products)):\n",
    "                reaction_valid = True\n",
    "\n",
    "                # Erstellung der Reaktion\n",
    "                reaction = Reaction(f'Random_Rxn_{i+1}')\n",
    "                reaction.name = f'Random Reaction {i+1}'\n",
    "\n",
    "                reaction.add_metabolites({\n",
    "                    met: -1.0 for met in reactants\n",
    "                })\n",
    "                reaction.add_metabolites({\n",
    "                    met: 1.0 for met in products\n",
    "                })\n",
    "\n",
    "                # 50% Chance, die Reaktion reversibel zu machen\n",
    "                if random.random() < 0.5:\n",
    "                    reaction.lower_bound = -1000.0\n",
    "                else:\n",
    "                    reaction.lower_bound = 0.0\n",
    "\n",
    "                reaction.upper_bound = 1000.0\n",
    "\n",
    "                random_reactions.append(reaction)\n",
    "\n",
    "    return random_reactions\n",
    "\n",
    "# Generierung von 2000 zufälligen Reaktionen + den Inversen\n",
    "random_reactions_list = generate_random_reactions(model, num_reactions=2000)\n",
    "\n",
    "# Anzahl der insgesamt generierten Reaktionen\n",
    "print(f\"\\nTotal number of random reactions generated: {len(random_reactions_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b007bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "import random\n",
    "\n",
    "def sample_reactions(model, n_reactions):\n",
    "  \n",
    "    # Filter reactions that do not end with '_in' or '_out'\n",
    "    valid_reactions = [rxn for rxn in model.reactions if not rxn.id.endswith('_in') and not rxn.id.endswith('_out')]\n",
    "\n",
    "    # Ensure that the model has enough valid reactions\n",
    "    if n_reactions > len(valid_reactions):\n",
    "        raise ValueError(\"Requested number of reactions exceeds the total number of valid reactions in the model\")\n",
    "\n",
    "    # Sample reactions randomly from the valid reactions list\n",
    "    sampled_reactions = random.sample(valid_reactions, n_reactions)\n",
    "\n",
    "    for rxn in sampled_reactions:\n",
    "        print(rxn.id)\n",
    "    \n",
    "    return sampled_reactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f84026af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_reactions_from_list(reactions_list, n_reactions):\n",
    "    \n",
    "    # Ensure the list has enough reactions to sample from\n",
    "    if n_reactions > len(reactions_list):\n",
    "        raise ValueError(\"Requested number of reactions exceeds the total number of reactions in the list\")\n",
    "\n",
    "    # Sample reactions randomly from the given list\n",
    "    sampled_reactions = random.sample(reactions_list, n_reactions)\n",
    "\n",
    "    for rxn in sampled_reactions:\n",
    "        print(rxn.id if hasattr(rxn, 'id') else rxn)  # Print the ID if the object has one\n",
    "\n",
    "    return sampled_reactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "780079c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_edit_distance(model1, model2):\n",
    "    \n",
    "    # Get sets of reaction IDs for both models\n",
    "    reactions_model1 = {rxn.id for rxn in model1.reactions}\n",
    "    reactions_model2 = {rxn.id for rxn in model2.reactions}\n",
    "    \n",
    "    # Calculate the symmetric difference (reactions present in one model but not the other)\n",
    "    differing_reactions = reactions_model1.symmetric_difference(reactions_model2)\n",
    "    \n",
    "    # The edit distance is the number of differing reactions\n",
    "    edit_distance = len(differing_reactions)\n",
    "    \n",
    "    return edit_distance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ee27b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_and_display(list1, list2, list3):\n",
    "    \n",
    "    # Erstellen des DataFrames\n",
    "    df = pd.DataFrame({'Scores': list1, 'Edit Distances': list2, 'Computation Count': list3})\n",
    "    \n",
    "    # Filtern: Entfernen von Zeilen mit NaN oder 0.0 in der ersten Liste\n",
    "    filtered_df = df.dropna(subset=['Scores'])\n",
    "    filtered_df = filtered_df[filtered_df['Scores'] != 0.0]\n",
    "    \n",
    "    # Ergebnis zurückgeben oder anzeigen\n",
    "    return filtered_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7878586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea959c20",
   "metadata": {},
   "source": [
    "## Generation of data points using sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee7a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "from cobra.sampling import sample\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Function to normalize a row based on A_in, excluding boundary reactions\n",
    "def normalize_row(row, normalization_id):\n",
    "    normalization_factor = row[normalization_id]\n",
    "    # Exclude boundary reactions (columns starting with \"EX_\" or ending with \"_out\")\n",
    "    filtered_row = {col: value for col, value in row.items() if (col.endswith(\"_in\") or col.endswith(\"_out\"))}\n",
    "    return {col: (value / normalization_factor) if normalization_factor != 0 else 0.0\n",
    "            for col, value in filtered_row.items()}\n",
    "\n",
    "\n",
    "def create_synthetic_datapoints(model, amount, normalization_id):\n",
    "    s = sample(model, amount)\n",
    "    \n",
    "    normalized_data = [normalize_row(row, normalization_id) for _, row in s.iterrows()]\n",
    "    \n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "013eba1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Reaction identifier</strong></td><td>EX_E_e</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Name</strong></td><td>exchange</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x284d495d0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Stoichiometry</strong></td>\n",
       "                <td>\n",
       "                    <p style='text-align:right'>E_e <=></p>\n",
       "                    <p style='text-align:right'><=></p>\n",
       "                </td>\n",
       "            </tr><tr>\n",
       "                <td><strong>GPR</strong></td><td></td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Lower bound</strong></td><td>-1000.0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Upper bound</strong></td><td>1000.0</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<Reaction EX_E_e at 0x284d495d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_gen = model.copy()\n",
    "\n",
    "# Exchange Reaktionen für extracelluläre Metaboliten\n",
    "model_data_gen.add_boundary(A_e, type=\"exchange\")\n",
    "model_data_gen.add_boundary(B_e, type=\"exchange\")\n",
    "model_data_gen.add_boundary(D_e, type=\"exchange\")\n",
    "model_data_gen.add_boundary(E_e, type=\"exchange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb0f8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "\n",
    "def check_for_deadends(model):    \n",
    "\n",
    "    \n",
    "    # Lists for results\n",
    "    upstream_no_consumption_roots = []\n",
    "    downstream_no_production_roots = []\n",
    "\n",
    "    # Initialize dictionaries for production and consumption of metabolites\n",
    "    metabolite_produced = {met: False for met in model.metabolites if met.compartment == 'c'}\n",
    "    metabolite_consumed = {met: False for met in model.metabolites if met.compartment == 'c'}\n",
    "\n",
    "    # Iterate over all reactions in the model\n",
    "    for reaction in model.reactions:\n",
    "        if reaction.reversibility:\n",
    "            #print(reaction)\n",
    "            # If reversible, treat all metabolites as both reactants and products\n",
    "            for met in reaction.metabolites:\n",
    "                metabolite_produced[met] = True\n",
    "                metabolite_consumed[met] = True\n",
    "        else:\n",
    "            # Metabolites produced in this reaction\n",
    "            for product in reaction.products:\n",
    "                #print(reaction.products)\n",
    "                if product.compartment == 'c':  # Only consider intracellular metabolites\n",
    "                    metabolite_produced[product] = True\n",
    "\n",
    "            # Metabolites consumed in this reaction\n",
    "            for reactant in reaction.reactants:\n",
    "                \n",
    "                if reactant.compartment == 'c':  # Only consider intracellular metabolites\n",
    "                    metabolite_consumed[reactant] = True\n",
    "\n",
    "    # Determine Upstream No-Consumption Roots (produced but not consumed)\n",
    "    for met, produced in metabolite_produced.items():\n",
    "        if produced and not metabolite_consumed[met]:\n",
    "            upstream_no_consumption_roots.append(met.id)\n",
    "\n",
    "    # Determine Downstream No-Production Roots (consumed but not produced)\n",
    "    for met, consumed in metabolite_consumed.items():\n",
    "        if consumed and not metabolite_produced[met]:\n",
    "            downstream_no_production_roots.append(met.id)\n",
    "\n",
    "    #print(\"Upstream No-Consumption Roots:\", upstream_no_consumption_roots)\n",
    "    #print(\"Downstream No-Production Roots:\", downstream_no_production_roots)\n",
    "\n",
    "    return len(upstream_no_consumption_roots) + len(downstream_no_production_roots)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66159a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_datapoints(datapoints, reaction_list):\n",
    "    \n",
    "    \n",
    "    ids = [reaction.id for reaction in reaction_list]\n",
    "    \n",
    "    filtered_data = []\n",
    "\n",
    "    for datapoint in datapoints:\n",
    "        filtered_datapoint = {key: value for key, value in datapoint.items() if key in ids}\n",
    "        filtered_data.append(filtered_datapoint)\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32efe572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def evaluate_reaction_subsets(model, experimental_data, random_reactions, num_removed):\n",
    "    \n",
    "    \n",
    "    threshold = len(experimental_data)/10 * 3e-7\n",
    "    \n",
    "    # Step 1: Remove 2 reactions from the model\n",
    "    model_copy = model.copy()\n",
    "    valid_reactions = [rxn for rxn in model_copy.reactions if not rxn.id.endswith('_in') and not rxn.id.endswith('_out')]\n",
    "    removed_reactions = random.sample(valid_reactions, num_removed)\n",
    "    model_copy.remove_reactions(removed_reactions)\n",
    "    print(model_copy.reactions)\n",
    "\n",
    "    experimental_data = filter_datapoints(experimental_data, model_copy.reactions)\n",
    "    \n",
    "    # Step 2: Assemble reaction pool of reactions that can be added\n",
    "    reaction_pool = removed_reactions + random_reactions\n",
    "\n",
    "    # Step 3: Evaluate subsets of size 2 and 3\n",
    "    adequate_subsets_count = 0\n",
    "    num_subsets_unblocked = 0\n",
    "    for subset_size in [2, 3]:\n",
    "        for subset in combinations(reaction_pool, subset_size):\n",
    "            # Add the subset of reactions to the model\n",
    "            temp_model = model_copy.copy()\n",
    "            temp_model.add_reactions(subset)\n",
    "\n",
    "            # Evaluate the score\n",
    "            S = get_stoichiometric_matrix(temp_model)\n",
    "            score, _ = least_square_min(temp_model, S, experimental_data)\n",
    "            \n",
    "            # Check if the score meets the criteria\n",
    "            if score < threshold and score != 0.0:\n",
    "                adequate_subsets_count += 1\n",
    "            \n",
    "                num_deadends = check_for_deadends(temp_model)\n",
    "                if num_deadends == 0:\n",
    "                    num_subsets_unblocked += 1\n",
    "                \n",
    "    return adequate_subsets_count, num_subsets_unblocked\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94515678",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "472b27bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_random_reacs = generate_random_reactions(model, 13)\n",
    "#remove_reacs = sample_reactions(model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6f2178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9b6fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data20 = create_synthetic_datapoints(model_data_gen, 20, \"r1_in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0868ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "510bef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data100 = create_synthetic_datapoints(model_data_gen, 100, \"r1_in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b163e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c449b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data500 = create_synthetic_datapoints(model_data_gen, 500, \"r1_in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23dba891",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(17)\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af00b4fb",
   "metadata": {},
   "source": [
    "## Evaluating number of adequate subsets for different experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b93fc5ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Reaction r1_in at 0x283195990>, <Reaction r2 at 0x284d4a990>, <Reaction r3 at 0x28543c810>, <Reaction r4_out at 0x28543c910>, <Reaction r5 at 0x28543e050>, <Reaction r8r_out at 0x28543e2d0>, <Reaction r9_out at 0x28543e490>]\n"
     ]
    }
   ],
   "source": [
    "num_adequate_subsets_efm, num_unblocked_efm = evaluate_reaction_subsets(model, experimental_data_zeropadded_out, test_random_reacs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7efdab24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subsets with adequate scores: 73\n",
      "Number of unblocked models: 73\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of subsets with adequate scores: {num_adequate_subsets_efm}\")\n",
    "print(f\"Number of unblocked models: {num_unblocked_efm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b855af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(17)\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17b32a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Reaction r1_in at 0x2866fbd10>, <Reaction r2 at 0x286700090>, <Reaction r3 at 0x286700210>, <Reaction r4_out at 0x286700390>, <Reaction r5 at 0x286700510>, <Reaction r8r_out at 0x2867009d0>, <Reaction r9_out at 0x2866fb890>]\n",
      "Number of subsets with adequate scores: 78\n",
      "Number of unblocked models: 78\n"
     ]
    }
   ],
   "source": [
    "num_adequate_subsets20, num_unblocked_20 = evaluate_reaction_subsets(model, synth_data20, test_random_reacs, 2)\n",
    "print(f\"Number of subsets with adequate scores: {num_adequate_subsets20}\")\n",
    "print(f\"Number of unblocked models: {num_unblocked_20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "150b1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(17)\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "225f4f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Reaction r1_in at 0x2871ce510>, <Reaction r2 at 0x2871af3d0>, <Reaction r3 at 0x28598f090>, <Reaction r4_out at 0x2871cdd10>, <Reaction r5 at 0x287267cd0>, <Reaction r8r_out at 0x287265010>, <Reaction r9_out at 0x287266490>]\n",
      "Number of subsets with adequate scores: 74\n",
      "Number of unblocked models: 74\n"
     ]
    }
   ],
   "source": [
    "num_adequate_subsets100, num_unblocked_100 = evaluate_reaction_subsets(model, synth_data100, test_random_reacs, 2)\n",
    "print(f\"Number of subsets with adequate scores: {num_adequate_subsets100}\")\n",
    "print(f\"Number of unblocked models: {num_unblocked_100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b305b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(17)\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6d2a1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Reaction r1_in at 0x28574fe10>, <Reaction r2 at 0x28574cf90>, <Reaction r3 at 0x28574ce90>, <Reaction r4_out at 0x28574d0d0>, <Reaction r5 at 0x28574cc90>, <Reaction r8r_out at 0x28574cb90>, <Reaction r9_out at 0x28574c8d0>]\n",
      "Number of subsets with adequate scores: 74\n",
      "Number of unblocked models: 74\n"
     ]
    }
   ],
   "source": [
    "num_adequate_subsets500, num_unblocked_500 = evaluate_reaction_subsets(model, synth_data500, test_random_reacs, 2)\n",
    "print(f\"Number of subsets with adequate scores: {num_adequate_subsets500}\")\n",
    "print(f\"Number of unblocked models: {num_unblocked_500}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2b2e0",
   "metadata": {},
   "source": [
    "Different Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01c4fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(23)\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c34e4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Reaction r1_in at 0x28619e9d0>, <Reaction r3 at 0x28567f090>, <Reaction r4_out at 0x28619e450>, <Reaction r6r at 0x28619c990>, <Reaction r7 at 0x28619c8d0>, <Reaction r8r_out at 0x28619cd10>, <Reaction r9_out at 0x28619c5d0>]\n",
      "Number of subsets with adequate scores: 335\n",
      "Number of unblocked models: 335\n"
     ]
    }
   ],
   "source": [
    "num_adequate_subsets_efm23, num_unblocked_efm_23 = evaluate_reaction_subsets(model, experimental_data_zeropadded_out, test_random_reacs, 2)\n",
    "print(f\"Number of subsets with adequate scores: {num_adequate_subsets_efm23}\")\n",
    "print(f\"Number of unblocked models: {num_unblocked_efm_23}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e3ed56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(23)\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99efaa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Reaction r1_in at 0x285eca210>, <Reaction r3 at 0x285eca150>, <Reaction r4_out at 0x285eca250>, <Reaction r6r at 0x285ecaf10>, <Reaction r7 at 0x285ecaf90>, <Reaction r8r_out at 0x285ec85d0>, <Reaction r9_out at 0x285ec8b90>]\n",
      "Number of subsets with adequate scores: 333\n",
      "Number of unblocked models: 333\n"
     ]
    }
   ],
   "source": [
    "num_adequate_subsets20_23, num_unblocked_20_23 = evaluate_reaction_subsets(model, synth_data20, test_random_reacs, 2)\n",
    "print(f\"Number of subsets with adequate scores: {num_adequate_subsets20_23}\")\n",
    "print(f\"Number of unblocked models: {num_unblocked_20_23}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68daa333",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(23)\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0b4dcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Reaction r1_in at 0x285f60c50>, <Reaction r3 at 0x285f63cd0>, <Reaction r4_out at 0x285f60e90>, <Reaction r6r at 0x285f61650>, <Reaction r7 at 0x285f602d0>, <Reaction r8r_out at 0x285f60150>, <Reaction r9_out at 0x285f63f10>]\n",
      "Number of subsets with adequate scores: 346\n",
      "Number of unblocked models: 346\n"
     ]
    }
   ],
   "source": [
    "num_adequate_subsets100_23, num_unblocked_100_23 = evaluate_reaction_subsets(model, synth_data100, test_random_reacs, 2)\n",
    "print(f\"Number of subsets with adequate scores: {num_adequate_subsets100_23}\")\n",
    "print(f\"Number of unblocked models: {num_unblocked_100_23}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e4e2cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(23)\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b57c89f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Reaction r1_in at 0x285f60cd0>, <Reaction r3 at 0x285f63e10>, <Reaction r4_out at 0x285dbac50>, <Reaction r6r at 0x285db8b10>, <Reaction r7 at 0x285db95d0>, <Reaction r8r_out at 0x285db9ed0>, <Reaction r9_out at 0x286418c90>]\n",
      "Number of subsets with adequate scores: 348\n",
      "Number of unblocked models: 348\n"
     ]
    }
   ],
   "source": [
    "num_adequate_subsets500_23, num_unblocked_500_23 = evaluate_reaction_subsets(model, synth_data500, test_random_reacs, 2)\n",
    "print(f\"Number of subsets with adequate scores: {num_adequate_subsets500_23}\")\n",
    "print(f\"Number of unblocked models: {num_unblocked_500_23}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f6c022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "928ba8cb",
   "metadata": {},
   "source": [
    "## Evaluation model reconstruction taking into account internal flux values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ede5d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "from cobra.sampling import sample\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Function to normalize a row based on a normalization id, excluding boundary reactions\n",
    "def normalize_row_internal(row, normalization_id):\n",
    "    normalization_factor = row[normalization_id]\n",
    "    # Exclude boundary reactions (columns starting with \"EX_\" or ending with \"_out\")\n",
    "    filtered_row = {col: value for col, value in row.items() if not (col.startswith(\"EX_\"))}\n",
    "    return {col: (value / normalization_factor) if normalization_factor != 0 else 0.0\n",
    "            for col, value in filtered_row.items()}\n",
    "\n",
    "\n",
    "def create_synthetic_datapoints_internal(model, amount, normalization_id):\n",
    "    s = sample(model, amount)\n",
    "    \n",
    "    normalized_data = [normalize_row_internal(row, normalization_id) for _, row in s.iterrows()]\n",
    "    \n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92a162ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3993f70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'r1_in': 1.0, 'r2': 0.251411895982439, 'r3': 0.3089745105705202, 'r4_out': 0.47836539858353555, 'r5': 0.7485881040175594, 'r6r': 0.05756261458808033, 'r7': 0.16939088801301433, 'r8r_out': -0.5216346014164654, 'r9_out': 0.3089745105705202}, {'r1_in': 1.0, 'r2': 0.07260286846284122, 'r3': 0.721849922334519, 'r4_out': 0.7290900475099578, 'r5': 0.9273971315371572, 'r6r': 0.6492470538716782, 'r7': 0.007240125175437548, 'r8r_out': -0.27090995249004024, 'r9_out': 0.721849922334519}, {'r1_in': 1.0, 'r2': 0.6523473466570071, 'r3': 0.05161825411092367, 'r4_out': 0.9483571989511526, 'r5': 0.34765265334299067, 'r6r': -0.6007290925460829, 'r7': 0.8967389448402269, 'r8r_out': -0.05164280104884401, 'r9_out': 0.05161825411092367}, {'r1_in': 1.0, 'r2': 0.9207240642659905, 'r3': 0.4901316463442748, 'r4_out': 1.1007338776593896, 'r5': 0.07927593573400625, 'r6r': -0.43059241792171354, 'r7': 0.6106022313151098, 'r8r_out': 0.10073387765938996, 'r9_out': 0.4901316463442748}, {'r1_in': 1.0, 'r2': 0.42982373805983465, 'r3': 0.41711381539726244, 'r4_out': 1.3929374382525992, 'r5': 0.5701762619401616, 'r6r': -0.012709922662568571, 'r7': 0.9758236228553335, 'r8r_out': 0.3929374382526002, 'r9_out': 0.41711381539726244}, {'r1_in': 1.0, 'r2': 0.7778166126215392, 'r3': 0.308389023156885, 'r4_out': 1.01294164412772, 'r5': 0.2221833873784567, 'r6r': -0.4694275894646469, 'r7': 0.7045526209708297, 'r8r_out': 0.012941644127718206, 'r9_out': 0.308389023156885}, {'r1_in': 1.0, 'r2': 0.20845796799322294, 'r3': 0.45850539461515666, 'r4_out': 1.320293987658825, 'r5': 0.7915420320067716, 'r6r': 0.2500474266219396, 'r7': 0.8617885930436652, 'r8r_out': 0.3202939876588281, 'r9_out': 0.45850539461515666}, {'r1_in': 1.0, 'r2': 0.18628015751269145, 'r3': 0.01974089579757694, 'r4_out': 2.250927979633514, 'r5': 0.8137198424873071, 'r6r': -0.16653926171511335, 'r7': 2.2311870838359393, 'r8r_out': 1.25092797963352, 'r9_out': 0.01974089579757694}, {'r1_in': 1.0, 'r2': 0.06212507263915183, 'r3': 0.574194010080999, 'r4_out': 0.6361757287192461, 'r5': 0.9378749273608524, 'r6r': 0.5120689374418446, 'r7': 0.06198171863825235, 'r8r_out': -0.363824271280752, 'r9_out': 0.574194010080999}, {'r1_in': 1.0, 'r2': 0.2689467684616829, 'r3': 0.1359137098624563, 'r4_out': 0.8259786374041224, 'r5': 0.7310532315383115, 'r6r': -0.13303305859922634, 'r7': 0.6900649275416663, 'r8r_out': -0.1740213625958726, 'r9_out': 0.1359137098624563}, {'r1_in': 1.0, 'r2': 0.9626419549987407, 'r3': 0.7590068411977573, 'r4_out': 1.5042549208416471, 'r5': 0.03735804500125754, 'r6r': -0.203635113800984, 'r7': 0.7452480796438911, 'r8r_out': 0.5042549208416499, 'r9_out': 0.7590068411977573}, {'r1_in': 1.0, 'r2': 0.7199801190195376, 'r3': 0.5670131762142598, 'r4_out': 1.1882164836218976, 'r5': 0.28001988098045744, 'r6r': -0.15296694280527978, 'r7': 0.6212033074076363, 'r8r_out': 0.18821648362189808, 'r9_out': 0.5670131762142598}, {'r1_in': 1.0, 'r2': 0.3217377933422042, 'r3': 0.24983605544978454, 'r4_out': 1.303689682030899, 'r5': 0.6782622066578021, 'r6r': -0.07190173789242234, 'r7': 1.0538536265811163, 'r8r_out': 0.30368968203089464, 'r9_out': 0.24983605544978454}, {'r1_in': 1.0, 'r2': 0.7315275571425289, 'r3': 0.9155504037085918, 'r4_out': 1.121771380045836, 'r5': 0.2684724428574763, 'r6r': 0.18402284656606, 'r7': 0.20622097633724742, 'r8r_out': 0.12177138004583261, 'r9_out': 0.9155504037085918}, {'r1_in': 1.0, 'r2': 0.1032964958567606, 'r3': 0.07610318843306176, 'r4_out': 2.763344753280252, 'r5': 0.8967035041432475, 'r6r': -0.027193307423707576, 'r7': 2.6872415648471994, 'r8r_out': 1.7633447532802518, 'r9_out': 0.07610318843306176}, {'r1_in': 1.0, 'r2': 0.16158574418867314, 'r3': 0.391342565987258, 'r4_out': 1.0433157031459928, 'r5': 0.8384142558113252, 'r6r': 0.2297568217985813, 'r7': 0.6519731371587375, 'r8r_out': 0.04331570314599768, 'r9_out': 0.391342565987258}, {'r1_in': 1.0, 'r2': 0.34792394017235323, 'r3': 0.10098678577070629, 'r4_out': 1.138190797025201, 'r5': 0.652076059827651, 'r6r': -0.2469371544016487, 'r7': 1.0372040112544942, 'r8r_out': 0.13819079702520326, 'r9_out': 0.10098678577070629}, {'r1_in': 1.0, 'r2': 0.8932208538150136, 'r3': 0.5062553982074043, 'r4_out': 1.4950214344690886, 'r5': 0.10677914618499192, 'r6r': -0.3869654556076124, 'r7': 0.9887660362616889, 'r8r_out': 0.49502143446909685, 'r9_out': 0.5062553982074043}, {'r1_in': 1.0, 'r2': 0.37547583528799744, 'r3': 0.6574233134532829, 'r4_out': 0.9704667214991823, 'r5': 0.6245241647120053, 'r6r': 0.2819474781652835, 'r7': 0.31304340804590164, 'r8r_out': -0.029533278500811458, 'r9_out': 0.6574233134532829}, {'r1_in': 1.0, 'r2': 0.06344075299708246, 'r3': 0.2142477384524262, 'r4_out': 1.5303013316303669, 'r5': 0.9365592470029255, 'r6r': 0.15080698545533588, 'r7': 1.316053593177944, 'r8r_out': 0.5303013316303837, 'r9_out': 0.2142477384524262}]\n"
     ]
    }
   ],
   "source": [
    "synth_data_internal42 = create_synthetic_datapoints_internal(model_data_gen, 20, \"r1_in\")\n",
    "\n",
    "print(synth_data_internal42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f01e1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(17)\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e98c381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Reaction r1_in at 0x285c28650>, <Reaction r2 at 0x285c28690>, <Reaction r3 at 0x285c28450>, <Reaction r4_out at 0x285c2b4d0>, <Reaction r5 at 0x285c2b610>, <Reaction r8r_out at 0x285c2b150>, <Reaction r9_out at 0x285c29410>]\n",
      "Number of subsets with adequate scores: (41, 41)\n"
     ]
    }
   ],
   "source": [
    "num_adequate_subsets_internal17 = evaluate_reaction_subsets(model, synth_data_internal42, test_random_reacs, 2)\n",
    "print(f\"Number of subsets with adequate scores: {num_adequate_subsets_internal17}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39d3acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(23)\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e16bbd13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Reaction r1_in at 0x2855eab50>, <Reaction r3 at 0x2854fcd50>, <Reaction r4_out at 0x2854fdb50>, <Reaction r6r at 0x2854fcb50>, <Reaction r7 at 0x2854fe010>, <Reaction r8r_out at 0x2854fcad0>, <Reaction r9_out at 0x2854fff90>]\n",
      "Number of subsets with adequate scores: (56, 56)\n"
     ]
    }
   ],
   "source": [
    "num_adequate_subsets_internal23 = evaluate_reaction_subsets(model, synth_data_internal42, test_random_reacs, 2)\n",
    "print(f\"Number of subsets with adequate scores: {num_adequate_subsets_internal23}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6b995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
